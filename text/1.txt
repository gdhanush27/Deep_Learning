from pyspark.sql import SparkSession
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml.classification import DecisionTreeClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml import Pipeline

spark = SparkSession.builder.appName("DecisionTreeExample").getOrCreate()
df=spark.read.csv("/content/cancer patient data sets.csv",header=True)
numeric_columns = ["Gender", "Age", "Alcohol use", "Dust Allergy"]
for column in numeric_columns:
    df = df.withColumn(column, df[column].cast("double"))
feature_columns = [ "Gender", "Age", "Alcohol use", "Dust Allergy"]
assembler = VectorAssembler(inputCols=feature_columns, outputCol="features")
label_indexer = StringIndexer(inputCol="Level", outputCol="label")
dt = DecisionTreeClassifier(featuresCol="features", labelCol="label")
pipeline = Pipeline(stages=[assembler, label_indexer, dt])
(training_data, test_data) = df.randomSplit([0.8, 0.2], seed=42)


model = pipeline.fit(training_data)
predictions = model.transform(test_data)
evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)


paramGrid = ParamGridBuilder()\
            .addGrid(dt.maxDepth, [3,5,7])\
            .addGrid(dt.minInstancesPerNode, [1,3,5])\
            .build()
crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid,
                      evaluator=MulticlassClassificationEvaluator(
                      labelCol='label', predictionCol='prediction', metricName='accuracy'),
                      numFolds=5)
cvModel = crossval.fit(training_data)
best_model = cvModel.bestModel
predictions = best_model.transform(test_data)
evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)