from sklearn.datasets import make_classification
import pandas as pd
import numpy as np
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras import layers, losses
from sklearn.metrics import classification_report 
X, y = make_classification(n_samples=100000, n_features=32,n_informative=32,n_redundant=0, n_repeated=0, n_classes=2,n_clusters_per_class=1,weights=[0.995, 0.005],class_sep=0.5, random_state=0)

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)
X_train_normal = X_train[np.where(y_train == 0)]
input = tf.keras.layers.Input(shape=(32,))# Encoder layers
encoder = tf.keras.Sequential([layers.Dense(16, activation="relu"),layers.Dense(8, activation='relu'),layers.Dense(4, activation='relu')])(input)
decoder = tf.keras.Sequential([layers.Dense(8, activation='relu'),layers.Dense(16, activation='relu'),layers.Dense(32, activation='sigmoid')])(encoder)
autoencoder = tf.keras.Model(inputs=input, outputs=decoder)
autoencoder.compile(optimizer='adam', loss='mae')
history = autoencoder.fit(X_train_normal, X_train_normal,epochs=20,batch_size=64,validation_data=(X_test, X_test),shuffle=True)
plt.plot(history.history['loss'], label='Training  Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
prediction = autoencoder.predict(X_test)
prediction_loss = tf.keras.losses.mae(prediction, X_test)
loss_threshold = np.percentile(prediction_loss, 98)
print(f'The prediction loss threshold for 2% of outliers is {loss_threshold:.2f}')
sns.histplot(prediction_loss, bins=30, alpha=0.8)
threshold_prediction = [0 if i < loss_threshold else 1 for i in prediction_loss]
print(classification_report(y_test, threshold_prediction))
